# An√°lisis y Predicci√≥n de Cancelaci√≥n de Clientes (Churn) üìà

## üöÄ Prop√≥sito del An√°lisis

El objetivo principal de este proyecto es **predecir la cancelaci√≥n (churn) de clientes** utilizando un conjunto de datos hist√≥rico. A trav√©s de un an√°lisis exhaustivo, buscamos identificar los **factores m√°s relevantes** que influyen en la decisi√≥n de un cliente de irse. La meta es proporcionar a la empresa informaci√≥n valiosa para desarrollar estrategias de retenci√≥n proactivas y efectivas.

---

## üìÇ Estructura del Proyecto

La estructura del proyecto est√° organizada de la siguiente manera:

* `TelecomX_parte2_LATAM.ipynb`: El cuaderno principal que abarca todas las etapas del proyecto, desde la carga de datos hasta la evaluaci√≥n de modelos.
* `datos_tratados.csv`: El conjunto de datos final, tratado y listo para el modelado.

---

## üìù Descripci√≥n del Proceso de Preparaci√≥n de Datos

### 1. Clasificaci√≥n de Variables üè∑Ô∏è
* **Variables Categ√≥ricas:** Variables como `gender`, `multiplelines`, `internetservice` y `paymentmethod` fueron tratadas mediante **codificaci√≥n One-Hot** para convertirlas en un formato num√©rico (0 y 1). Esto es esencial para que los modelos de Machine Learning puedan procesar esta informaci√≥n.
* **Variables Num√©ricas:** Variables como `tenure`, `charges.monthly` y `charges.total` se mantuvieron en su formato num√©rico original.

### 2. Normalizaci√≥n y Codificaci√≥n üõ†Ô∏è
* **Normalizaci√≥n:** Para el modelo de Regresi√≥n Log√≠stica, se aplic√≥ la normalizaci√≥n (`StandardScaler`) a las variables num√©ricas continuas. Esta etapa es crucial porque asegura que todas las caracter√≠sticas tengan la misma escala, evitando que variables con rangos de valores grandes (ej. `charges.total`) dominen el proceso de optimizaci√≥n del modelo.
* **Separaci√≥n de Datos:** El conjunto de datos se dividi√≥ en un **70% para entrenamiento** y un **30% para prueba**. Se utiliz√≥ el par√°metro `stratify=y` para asegurar que la proporci√≥n de clientes que cancelan (churn) fuera la misma en ambos conjuntos, lo cual es vital en un dataset desbalanceado.

---

## üß† Justificaciones de las Decisiones de Modelado

* **Manejo del Desbalance de Clases:** El conjunto de datos original estaba severamente desbalanceado. Para abordar esto, se opt√≥ por el m√©todo de **undersampling NearMiss** en el conjunto de entrenamiento. Esta t√©cnica se enfoca en las muestras de la clase mayoritaria que est√°n m√°s cerca de las de la clase minoritaria, lo que ayuda a que el modelo aprenda a diferenciar entre las clases en las zonas de riesgo.
* **Selecci√≥n de Modelos:** Se eligieron dos modelos con diferentes sensibilidades a la escala de los datos para comparar su rendimiento:
    * **Regresi√≥n Log√≠stica:** Requiere normalizaci√≥n, lo que nos permiti√≥ evaluar c√≥mo la estandarizaci√≥n afecta el desempe√±o del modelo.
    * **√Årbol de Decisi√≥n:** No requiere normalizaci√≥n, lo que lo hace un modelo robusto y f√°cil de interpretar en su forma original.
* **Evaluaci√≥n de M√©tricas:** En lugar de centrarnos solo en la exactitud (`accuracy`), se priorizaron m√©tricas como **Precisi√≥n**, **Recall** y **F1-score**, especialmente para la clase minoritaria (`churn`). Esto se debe a que un alto `accuracy` puede ser enga√±oso en un dataset desbalanceado, mientras que el `recall` mide la capacidad del modelo para detectar a todos los clientes que realmente cancelan, lo cual es de gran importancia para el negocio.

---

## üìà Ejemplos de Gr√°ficos e Insights


**Matriz de Correlaci√≥n:** Muestra la fuerte correlaci√≥n negativa entre `tenure` (antig√ºedad) y `churn`.


**Boxplot de Antig√ºedad vs. Churn:** Este gr√°fico visualiza que los clientes que cancelan tienen una antig√ºedad promedio significativamente m√°s baja que aquellos que no.


**Gr√°fico de Dispersi√≥n:** Muestra que los clientes que cancelan (`churn=1`) tienden a agruparse en la parte inferior izquierda, correspondiente a una baja antig√ºedad y un menor gasto total.

---

## ‚öôÔ∏è Instrucciones para Ejecutar el Cuaderno

Para ejecutar el an√°lisis completo, sigue estos pasos:

1.  **Instalar Bibliotecas:** Aseg√∫rate de tener las siguientes bibliotecas instaladas. Puedes hacerlo con `pip`:
    ```bash
    pip install pandas numpy scikit-learn seaborn matplotlib imbalanced-learn
    ```
2.  **Cargar los Datos:** Aseg√∫rate de que el archivo `datos_tratados.csv` se encuentre en la ra√≠z del repositorio.
3.  **Ejecutar el Cuaderno:** Abre el archivo `TelecomX_parte2_LATAM.ipynb` ubicado en la ra√≠z del repositorio y ejecutalo con Google Colab. A continuaci√≥n, ejecuta cada celda en orden.

¬°Con esto, podr√°s replicar el an√°lisis y obtener todos los insights del proyecto!
